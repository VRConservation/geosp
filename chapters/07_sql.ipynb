{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0846408b",
   "metadata": {},
   "source": [
    "# SQL\n",
    "\n",
    "The language you must learn for geospatial analysis!\n",
    "\n",
    "## New\n",
    "\n",
    "I have to admit I'm very new to using SQL for geospatial analysis but I am amazed at how easy it is to learn, how fast it analyzes large datasets, and how critical it is for data analysis. SQL really is the universal database management language, so geospatial aside, if you work with data, you need to learn how to use it.\n",
    "\n",
    "```{tip}\n",
    "When you perform a definition query in ArcGIS Pro or a data query in QGIS, SQL runs in the background. In fact, if you use ArcGIS Pro, open it up, double-click on a layer, open the def query function, and note that there's a little switch to convert the GUI to SQL. Create a query, then switch it to SQL to see the translation.\n",
    "```\n",
    "\n",
    "Add photo of a def query before and after in Arc (with and w/o SQL)\n",
    "\n",
    "## DuckDB\n",
    "\n",
    "We'll use [DuckDB](https://duckdb.org/) for examples in this chapter. The software is easy to install (takes seconds), fast, works seamlessly with many programming languages, including Python, R, and Javascript, and works without fuss. DuckDB also has a spatial extension to perform queries and analysis of geospatial data that we will look at in this chapter. The big advantage of DuckDB is its speed processing large datasets\n",
    "\n",
    "A special thank you to Quisheng Wu for the DuckDB tutorials/lectures from his [Geog-414 course](https://geog-414.gishub.org/), which has superb tutorials on Python, Earth Engine, DuckDB, and PostGIS.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Installation is straightforward: follow the instructions for the command line or Python at the DuckDB installation [page](http://gg.gg/1at9tp).\n",
    "\n",
    "## Wood processing\n",
    "\n",
    "Let's move to an example from the University of California's Woody Biomass Utilization Group's Biomass Power Plant [Database](http://gg.gg/1as7ti). First, import the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a34447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import duckdb\n",
    "import leafmap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa8859",
   "metadata": {},
   "source": [
    "Then, connect to the duckdb database and install httpfs and spatial extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database install httpfs, spatial\n",
    "con = duckdb.connect()\n",
    "con.install_extension(\"httpfs\")\n",
    "con.load_extension(\"httpfs\")\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f60a5",
   "metadata": {},
   "source": [
    "Read the sawmill .shp file and create the sawmill table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sawmill table from shp file and show\n",
    "con.sql('''\n",
    "    CREATE TABLE IF NOT EXISTS sawmill as\n",
    "    SELECT * FROM ST_Read('C:/Users/vance/Downloads/CurrentSawmill/Current_Wood_Facility_Database_Primary_Wood_Processing.shp')\n",
    "''')\n",
    "con.table('sawmill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd59f8d",
   "metadata": {},
   "source": [
    "```{tip} Duckdb sql can be run in the command line and through Python as we are doing here. There are several ways to do this, but wrapping the commands in con.sql with parenthesis and two sets of double or single quotes is easier to code and read.\n",
    "\n",
    "```\n",
    "\n",
    "![sawmill-all](https://i.imgur.com/ptLCP0F.png)\n",
    "\n",
    "View the sawmill table schema, then sum # sawmills by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sawmill table schema\n",
    "con.sql('''\n",
    "    DESCRIBE sawmill\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd639d8",
   "metadata": {},
   "source": [
    "![sawmill-schema](https://i.imgur.com/gM9AJtB.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum sawmills by county\n",
    "con.sql('''\n",
    "    SELECT County, COUNT(*) as Count\n",
    "    FROM sawmill\n",
    "    GROUP BY County\n",
    "    ORDER BY count DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335e8a2",
   "metadata": {},
   "source": [
    "![sawmill-county](https://i.imgur.com/GeX2mE6.png)\n",
    "\n",
    "Import the biomass database, then create the biomass table and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62dd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Biomass dataset\n",
    "con.sql(\"SELECT * FROM ST_Read('C:/Users/vance/Downloads/CurrentBiomass/Current_Wood_Facility_Database_Biomass.shp')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9669b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create biomass table from the shp file and show\n",
    "con.sql('''\n",
    "    CREATE TABLE IF NOT EXISTS biomass as\n",
    "    SELECT * FROM ST_Read('C:/Users/vance/Downloads/CurrentBiomass/Current_Wood_Facility_Database_Biomass.shp')\n",
    "''')\n",
    "con.table('sawmill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daafb0c",
   "metadata": {},
   "source": [
    "View the biomass table schema, then sum the total megawatts of the plants by county, rounding the total to 1 decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View biomass table schema\n",
    "con.sql('''\n",
    "    DESCRIBE biomass\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the total MW_Grid by county round to 1 decimal\n",
    "\n",
    "con.sql('''\n",
    "    SELECT County, ROUND(SUM(CAST(MW_Grid AS FLOAT)), 1) as Total_MW_Grid\n",
    "    FROM biomass\n",
    "    GROUP BY County\n",
    "    ORDER BY Total_MW_Grid DESC\n",
    "    LIMIT 15\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05752d",
   "metadata": {},
   "source": [
    "## Large datasets\n",
    "Coming soon!\n",
    "\n",
    "## Geospatial datasets\n",
    "Coming soon!\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **[GEOG-414](https://geog-414.gishub.org/book/duckdb/01_duckdb_intro.html)**. The DuckDB portion of the Geography 414 course from Quisheng Wu, UT Knoxville, is a definitive and recommended way to start with DuckDB.\n",
    "- **[Spatial SQL](https://spatial-sql.com/)**. Matt Forrest's text on using SQL in modern GIS is an excellent reference and starter for using SQL within a spatial context. Although the book could use an edit (many spelling errors) and better organization (figures disconnected from text), everything is in the book that you will need to become a spatial SQL expert.\n",
    "- **[SQL-QGIS Tip](https://twitter.com/spatialthoughts/status/1774833044396081189)**. You can use the 'Execute SQL' processing algorithm to run SQL queries on ANY vector layer within QGIS. Here's an example of calculating group statistics on a vector layer. This also allows you to run SQL queries in a model.\n",
    "- **[Mark Litwintschik](https://tech.marksblogg.com/duckdb-gis-spatial-extension.html)**. Mark has a great data and geospatial blog featuring several tutorials running the DuckDB spatial extension.\n",
    "\n",
    "<!-- \n",
    "## Notes\n",
    "[lonboard](https://github.com/developmentseed/lonboard)\n",
    "\n",
    "[overture map data](https://docs.overturemaps.org/) is mostly buildings and infrastructure\n",
    "\n",
    "[query data and load to kepler.gl](https://docs.overturemaps.org/examples/kepler-gl/) using duckdb\n",
    "\n",
    "[examples page](https://docs.overturemaps.org/examples/#13/47.6/-122.33/0/45) has more with duck\n",
    "\n",
    "[open geospatial](https://github.com/opengeos/geospatial-data-catalogs) datasets\n",
    "use the cleaned LEWO sets and upload them to a GitHub page\n",
    "\n",
    "youtube course from Freecode camp, note the outline: https://www.youtube.com/watch?v=mXW7JHJM34k\n",
    "\n",
    "[analyze millions of points](https://www.youtube.com/watch?v=ljzpm3Mrw-I) has nice duckdb analysis using h3 and connecting code to cli -->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
