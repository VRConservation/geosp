# R
R is the definitive programming language for data analysis and visualization in academia. But it's increasingly being used more broadly due to its ease of use and many analysis packages.

## Similarities
Javascript, Python, and R have strikingly similar code structure ({numref}`comparison`).

```{figure} /figures/rgee.png
:name: comparison

Javascript, Python, R code comparison. Adapted from [rgee](http://gg.gg/19zkau). Note that Python require additional commands to run Earth Engine.
```

In fact, it's similar enough to make each coding language organized in your head, almost like learning Spanish and Portuguese. It's probably better to focus on one or the other, but you may find that one language sometimes offers better packages, processes data more quickly than the other, or is preferred in a particular workplace.


```{tip} R has the somewhat annoying symbol for variables or assignment operator of <-, but you can quickly enter it using the keyboard shortcut Alt/Option and - (Alt and minus sign) in Windows/Mac.
```

## Installation
The [RStudio](https://posit.co/download/rstudio-desktop/) desktop IDE is very good and only requires a two stop installation of R and RStudio. The IDE has a terminal, code section, installs packages through search, a variable/file panel, and a preview window that will show maps, graphs, or other outputs.

If you don't want to install yet another IDE, you can run R through VS Code with a number of basic to bespoke options:

1. Install R from [CRAN](https://cran.rstudio.com/). 
2. Install the language server in R: 'install.packages("languageserver")'
3. Go to extensions and install the R Extension Pack by Yuki Ueda. This will install R (the coding language) and R-LSP (provides language support and autocomplete for commands).
4. Install extra packages such as [radian](https://github.com/randy3k/radian) to make R easier to use. See the notes in the R extension in VS Code for additional recommendations, links, and installation instructions. [This](https://medium.com/analytics-vidhya/a-fresh-start-for-r-in-vscode-ec61ed108cf6) article is a concise guide for setup. 

## EDA
The R library DataExplorer allows you to quickly perform exploratory data analysis (EDA) on datasets. I've adapted this section from a post in datascienceplus.com from [Raja 2018](https://datascienceplus.com/blazing-fast-eda-in-r-with-dataexplorer/).

If you want to fast forward to creating an html report that opens in your browser run the command `create_report()` after loading the package library and reading your dataset to a variable.

```{tip} **Package Installation**. If you're using RSTudio you can also install packages by going to the packages tab in the Files, Plots, Packages pane (default location lower right), select Packages, Install then enter the package name in the open window.

**Running R Script**. You can run each line of code entered by placing the cursor at the comment or line of code you want to run then clicking the Run button in the upper right of the code pane (default location upper left) or using control/command enter on your keyboard. You can also highlight an entire block or section of code and run it with the same command.
```

Install the Data Explorer package and load it

```
install.packages('DataExplorer')
library(DataExplorer)
```

Download the [chocoloate bar ratings](https://www.kaggle.com/datasets/rtatman/chocolate-bar-ratings/data) dataset from kaggle and copy it's path to wherever you store it.

```{tip}
If you use Windows OS, right clicking on a file and selecting copying the path to the file will create a file pathway with backslashes rather than forward slashes and create an error when you run `read.csv()`. Install [Path Copy Copy](https://pathcopycopy.github.io/) and then right click and select show more options then copy unix path.
```
Read the csv file, show the top 10, and total rows

```python
#read csv
cacao <- read.csv('./test/cacao.csv', header = T, stringsAsFactors = F)

#examine head and create summary statistics
head(cacao)
summary(cacao)
```

Running the head(cacao) line produces the following in the console

![head](https://i.imgur.com/TD3suZC.png)

It's messy but at least confirms the dataset loaded. The summary command gives more information

![summary](https://i.imgur.com/o0BJKFI.png)

A better visual summary can be produced using `plot_intro(cacao)` producing

![plot_intro](https://i.imgur.com/MqSenEN.png)

Note the summary stats show that the variable Cocoa.Percent is a character rather than a number due to the % sign attached to each value and the review date needs to be changed to character. To fix this error run the following:

```python
# Fix Cocoa.Percent character error
cacao$Cocoa.Percent = as.numeric(gsub('%','',cacao$Cocoa.Percent))  
cacao$Review.Date = as.character(cacao$Review.Date)
```
When you run head or summary again the Cocoa.Percent is now converted to numbers.

There are several functions to analyze and plot the dataset looking at categorical and continuous variables and other analyses. For example:

```python
# variable dimension strings: variables, variable type, and total number
plot_str(cacao)
# missing values for each variable
plot_missing(cacao)
# variable histograms
plot_histogram(cacao)
# variable density plots
plot_density(cacao)
# variable bar plots
plot_bar(cacao)
# multivariate correlationa analysis
plot_correlation(cacao, type = 'continuous','Review.Date')
```
For instance the histogram plot shows distribution values for all the continuous variables. In this case most cocoa percents are in the 70s and ratings cluster around three.

![histogram](https://i.imgur.com/S0UdRRz.png)

The simplified correlation analysis grouping Review.Dat shows weak relationship between Rating and Cocoa.Percent.

![correlation](https://i.imgur.com/ojVX5Hx.png)

The `create_report()` function will run all of the EDA commands above, convert the outputs to an html file then open the report in your default browser. This is useful if you want to enter one line and get a rapid summary of everything for the dataset. All of the above code runs very fast even with large datasets. More details on the package can be found at the [Introduction to DataExplorer site](https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html).

## lidR
Lidar (Light detection and ranging) frequently used for forest stand analysis. Let's explore the lidR package to show it's amazing 3d and analysis capabilities. Not only does the package come with a book with excellent instructions to demo the package functions, it also has a manageable sized las point cloud dataset {cite}`lidr`. The following examples are excerpted from the book.

If you don't have point cloud data, and don't want to use the provided dataset, the US Geological Service has a [Lidar Explorer](https://apps.nationalmap.gov/lidar-explorer/#/) offering downloads of publicly available lidar datasets across the United States. Define an ROI on the map and download the tiled laz files. Beware, even a single tile can be huge. I downloaded a single tile in Mendocino County, CA that was 1.3 gb in size and contained nearly 49 million points. By contrast the las dataset from the lidR book is 'only' 2 mb and has a little less than 38k points. 

```python
## Install lidR import, read las file and plot
install.packages('lidR')
library(lidR)
LASfile <- system.file("extdata", "MixedConifer.laz", package="lidR")
las <- readLAS(LASfile, select = "xyzr", filter = "-drop_z_below 0")
plot(las, bg = "white", size = 4)
```

This will give you a popup window showing the 3d point cloud of the lidar return in this dataset with highest values red and lowest blue. Since the point cloud appears to be of a forest stand, you can discern tree outlines. If you left click on the point cloud model you can rotate the dateset in 3 dimensions. Far out man!

<!-- <video controls src="/figures/3dmodel.mp4" title="3d Las"></video> -->

Rasterize a canopy height model and plot it. Not the highest tree show up in the lower right corner, same as the 3d mmodel.

```python
# Rasterize canopy height model
chm <- rasterize_canopy(las, 0.5, pitfree(subcircle = 0.2))
plot(chm, col = height.colors(50))
```
![rasterized_las](https://i.imgur.com/20jBlqP.png)

Locate the tree top centers

```python
# Locate the tree tops and plot
ttops <- locate_trees(las, lmf(ws = 5))
plot(sf::st_geometry(ttops), add = TRUE, pch = 3)
```
![centers](https://i.imgur.com/u4Edfbm.png)

You can also add the tree top centers to a 3d model

```python
# Add 3d tree tops
add_treetops3d(x, ttops)
```

<!-- <video controls src="/figures/tops.mp4" title="3d Treetops"></video> -->

Finally, you can add custom metrics with a geometry argument that shows each tree as a convex shaded by height:

```python
metrics <- crown_metrics(las, func = ccm, geom = "convex")
plot(metrics["z_max"], pal = hcl.colors)
```

Creates

![convexhulls](https://i.imgur.com/gelwCHp.png)

## DuckDB
Yes you can execute DuckDB in R! DuckDB everywhere and because it uses SQL syntax, it looks similar to Python.

Install DuckDB, import the library, and create an in-memory database

```python
# install and import duckdb
install.packages('duckdb')
library('duckdb')
con <- dbConnect(duckdb())
```

Create a simple table and insert two items into the table

```python
# create a table
dbExecute(con, "CREATE TABLE items(item VARCHAR, value DECIMAL(10, 2), count INTEGER)")
# insert two items into the table
dbExecute(con, "INSERT INTO items VALUES ('jeans', 20.0, 1), ('hammer', 42.2, 2)")
```

Write a query for the table and show it in the R console

```python
# Query and print to console
res <- dbGetQuery(con, "SELECT * FROM items")
print(res)
```
Gives the output

```
    item value count
1  jeans  20.0     1
2 hammer  42.2     2
```

## Resources
These examples barely scratch the surface of what is available for geospatial R. The following resources provide a deeper dive:

- **[Geocomputation with R](https://r.geocompx.org/)**. An excellent free and open source book hosted on Github and covers many aspects of geospatial analysis in R {cite}`lovelace`. **[Spatial Data Science with Applications in R](https://r-spatial.org/book/)** is another excellent resource {cite}`sds`. Both publications are great if you are new to R. Spatial Data Science is particularly good for explanations and figures accompanied by R codeblocks to show you how to put together the code.
- **[Neon intro to R](https://www.neonscience.org/resources/learning-hub/tutorials/packages-r)**. National Ecological Observatory Network from the US National Science Foundation introductory R tutorial.
- https://jean-romain.github.io/lidRbook/index.html. Notebook for the LidR module.
- **[Data Carpentry](https://datacarpentry.org/r-intro-geospatial/01-rstudio-intro/index.html)**. Data carprentry R module. Data carpentry also has an intro to geospatial [module](https://datacarpentry.org/lessons/#geospatial-curriculum).
- **[Introduction to Statistical Learning](https://www.statlearning.com/)**. Look! You can do statistical learning in R or Python - Bonus!
- **[r-spatial/rgee](https://github.com/r-spatial/rgee)**. An R library for Google Earth Engine. Chapter 6.4 of the Earth Engine Fundamentals and Applications is focused on the rgee package {cite}`eefa`.
- **[lidR](https://r-lidar.github.io/lidRbook)**. Online book for the lidR package.
